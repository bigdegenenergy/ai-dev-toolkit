name: OneFileLLM Content Aggregator

on:
  workflow_dispatch:
    inputs:
      sources:
        description: 'Input sources (space-separated URLs, paths, or GitHub repos)'
        required: true
        type: string
      output_name:
        description: 'Output filename (without extension)'
        required: false
        default: 'aggregated-content'
        type: string
      format:
        description: 'Output format override'
        required: false
        type: choice
        options:
          - auto
          - text
          - markdown
          - json
          - html
          - yaml
        default: auto
      crawl_depth:
        description: 'Max crawl depth for web URLs'
        required: false
        default: '3'
        type: string
      crawl_max_pages:
        description: 'Max pages to crawl'
        required: false
        default: '100'
        type: string

  # Allow calling from other workflows
  workflow_call:
    inputs:
      sources:
        description: 'Input sources (space-separated URLs, paths, or GitHub repos)'
        required: true
        type: string
      output_name:
        description: 'Output filename (without extension)'
        required: false
        default: 'aggregated-content'
        type: string
      format:
        description: 'Output format override'
        required: false
        type: string
        default: auto
      crawl_depth:
        description: 'Max crawl depth for web URLs'
        required: false
        default: '3'
        type: string
      crawl_max_pages:
        description: 'Max pages to crawl'
        required: false
        default: '100'
        type: string
    outputs:
      output_file:
        description: 'Path to the generated output file'
        value: ${{ jobs.aggregate.outputs.output_file }}
      token_count:
        description: 'Estimated token count'
        value: ${{ jobs.aggregate.outputs.token_count }}

jobs:
  aggregate:
    name: Aggregate Content
    runs-on: ubuntu-latest
    outputs:
      output_file: ${{ steps.run.outputs.output_file }}
      token_count: ${{ steps.run.outputs.token_count }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'tools/onefilellm/requirements.txt'

      - name: Install onefilellm
        run: |
          pip install -r tools/onefilellm/requirements.txt
          # Verify installation
          onefilellm --help || python -m onefilellm --help

      - name: Run onefilellm
        id: run
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Create output directory
          mkdir -p output

          # Build command arguments
          ARGS=""

          # Add format if not auto
          if [ "${{ inputs.format }}" != "auto" ]; then
            ARGS="$ARGS -f ${{ inputs.format }}"
          fi

          # Add crawl options
          ARGS="$ARGS --crawl-max-depth ${{ inputs.crawl_depth }}"
          ARGS="$ARGS --crawl-max-pages ${{ inputs.crawl_max_pages }}"

          # Run onefilellm and capture output
          echo "Running: onefilellm $ARGS ${{ inputs.sources }}"

          # Execute and save to file (disable clipboard in CI)
          onefilellm $ARGS ${{ inputs.sources }} > "output/${{ inputs.output_name }}.xml" 2>&1 || {
            # If direct output fails, try without redirect
            python -m onefilellm $ARGS ${{ inputs.sources }} > "output/${{ inputs.output_name }}.xml" 2>&1
          }

          # Check if output was generated
          if [ -f "output/${{ inputs.output_name }}.xml" ]; then
            echo "output_file=output/${{ inputs.output_name }}.xml" >> $GITHUB_OUTPUT

            # Estimate token count (rough approximation: chars / 4)
            CHARS=$(wc -c < "output/${{ inputs.output_name }}.xml")
            TOKENS=$((CHARS / 4))
            echo "token_count=$TOKENS" >> $GITHUB_OUTPUT

            echo "Generated output with ~$TOKENS estimated tokens"
            echo "File size: $(du -h output/${{ inputs.output_name }}.xml | cut -f1)"
          else
            echo "Error: No output generated"
            exit 1
          fi

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.output_name }}
          path: output/${{ inputs.output_name }}.xml
          retention-days: 30

      - name: Summary
        run: |
          echo "## OneFileLLM Output Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Sources:** \`${{ inputs.sources }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Output file:** \`${{ steps.run.outputs.output_file }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Estimated tokens:** ~${{ steps.run.outputs.token_count }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**File size:** $(du -h output/${{ inputs.output_name }}.xml | cut -f1)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Download the artifact above to use with your LLM." >> $GITHUB_STEP_SUMMARY
