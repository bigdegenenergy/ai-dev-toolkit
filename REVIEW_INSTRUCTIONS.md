# ⚠️ REVIEW INSTRUCTIONS

> Generated by Gemini

```json
{
  "review": {
    "summary": "This PR introduces a comprehensive suite of AI-driven workflows. While the architecture is ambitious, there are critical correctness issues in the GitHub Actions logic (specifically regarding git context in comment triggers) and potential configuration risks with Model IDs. The security model relies heavily on maintainer gates, but prompt injection remains a risk for the write-capable agents.",
    "decision": "REQUEST_CHANGES"
  },
  "issues": [
    {
      "id": 1,
      "severity": "critical",
      "file": ".github/workflows/claude-research-implement.yml",
      "line": 0,
      "title": "Incorrect Git Checkout Context for Issue Comments",
      "description": "Workflows triggered by `issue_comment` do not have `github.head_ref` or `github.event.pull_request` populated in the context (only `github.event.issue.pull_request` as a URL). Using standard checkout actions without explicitly fetching the PR's ref via API will result in checking out the default branch (usually `main`) or a detached HEAD, rather than the PR branch. This will cause the AI to generate code against the wrong context or fail to push changes back to the PR.",
      "suggestion": "Use a step to fetch the PR details (e.g., via `gh pr checkout ${{ github.event.issue.number }}`) or manually resolve the ref from the issue API before the checkout/implementation steps."
    },
    {
      "id": 2,
      "severity": "important",
      "file": ".github/workflows/claude-auto-implement.yml",
      "line": 0,
      "title": "Prompt Injection Risk via Issue Body",
      "description": "The workflow injects the raw Issue Body (`${{ env.ISSUE_BODY }}`) into the prompt for the AI agent, which has `contents: write` permissions. While the workflow is gated by a maintainer applying a label, a malicious user could craft an issue body containing adversarial instructions (Prompt Injection) that override the system prompt. If the maintainer labels it without careful inspection of the hidden text, the AI could execute malicious commands.",
      "suggestion": "Wrap the user input in explicit XML tags (e.g., `<user_request>`) in the system prompt and instruct the model to treat content within those tags purely as data/context, ignoring any instructions contained therein. Consider adding a warning in the workflow logs."
    },
    {
      "id": 3,
      "severity": "important",
      "file": ".github/workflows/claude.yml",
      "line": 0,
      "title": "Potential Invalid Model Configuration",
      "description": "The workflows reference `model: claude-sonnet-4-20250514`. Unless this refers to a strictly internal or future-dated model available to your specific organization, this Model ID likely does not exist on the public Anthropic API, which would cause all AI jobs to fail immediately.",
      "suggestion": "Verify the Model ID against the currently available options (e.g., `claude-3-5-sonnet-20240620`) or ensure this specific version tag is valid for your API access level."
    },
    {
      "id": 4,
      "severity": "suggestion",
      "file": ".github/workflows/claude.yml",
      "line": 0,
      "title": "Performance Impact of Full Git History",
      "description": "The workflows use `fetch-depth: 0` (full history). For the 'Implementation' and 'Review' tasks, the agent typically only needs the current head and perhaps the diff context. Fetching full history is expensive and slow for larger repositories.",
      "suggestion": "Reduce `fetch-depth` to a reasonable limit (e.g., `1` or `10`) unless the AI explicitly requires full historical context for tasks like 'Researching evolution of a feature'."
    }
  ]
}
```